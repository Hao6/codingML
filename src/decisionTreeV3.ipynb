{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "- CART(分类与回归树)算法\n",
    "    1. CART在分类与回归两类问题上有着不同的节点分割策略\n",
    "    2. CART分类的分裂策略是二分，gini指数最小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    # 根据标签序列计算gini指数\n",
    "    def get_gini(self, labels_list, n_samples):\n",
    "        \"\"\"\n",
    "        :labels_list, ndarray, 标签列表、数组\n",
    "        :n_samples, int, 总的类别数\n",
    "        计算信息熵\n",
    "        \"\"\"\n",
    "        _, label_counts = np.unique(labels_list, return_counts=True)\n",
    "        p = label_counts * 1.0 / n_samples\n",
    "        return 1 - np.sum(np.power(p, 2))\n",
    "\n",
    "    # 根据标签类别数计算gini指数\n",
    "    def get_gini_with_counts(self, labels_count, n_samples):\n",
    "        \"\"\"\n",
    "        :labels_count, ndarray, 标签数量列表、数组\n",
    "        :n_samples, int, 总的标签数\n",
    "        计算信息熵\n",
    "        \"\"\"\n",
    "        p = labels_count * 1.0 / n_samples\n",
    "        return 1 - np.sum(np.power(p, 2))\n",
    "\n",
    "    def __init__(self, data_x, data_y, attr_is_dispersed):\n",
    "        '''\n",
    "        :data_x: ndarray, 标签化的数据集x\n",
    "        :data_y: ndarray, 标签化的数据集y\n",
    "        :attr_is_dispersed, ndarray, 属性是否为离散的，例如[1,0,1,0,1],则表示下标0、2、4的属性是离散的，\n",
    "        '''\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.next_nodes = {}  # 存储子节点\n",
    "        self.is_leaf = None\n",
    "        self.seg_attr_index = -1  # 在该节点选择的分割属性\n",
    "        self.seg_attr_value = -1  # 分割属性值，返回属性分割值\n",
    "\n",
    "        n_samples, n_features = data_x.shape\n",
    "        # 当前节点数据数不大于1、数据标签y全部一致的情况下，认定为子节点\n",
    "        uniques_y = np.unique(self.data_y, return_counts=False)\n",
    "        if n_samples <= 1 or len(uniques_y) == 1:\n",
    "            self.is_leaf = True\n",
    "        else:  # 非叶子节点\n",
    "            #             gain = self.get_Information_entropy(self.data_y, n_samples)  # 熵\n",
    "            self.is_leaf = False\n",
    "            # 根据可用分割属性segmentation_attr，以及属性离散/连续记录表attr_is_dispersed来确定最优\n",
    "            # 分割属性,默认采用信息增益的方式，ID3算法\n",
    "            temp_gini = 1  # 保存最小的gini指数\n",
    "            temp_attr_index = -1  # 保存按哪个属性分割可以得到最小的gini指数\n",
    "\n",
    "            # 返回包含分割点的属性值\n",
    "            temp_attr_seg = None\n",
    "            # 如果优属性是连续的，则返回升序属性序列的分割点下标，方便后续计算\n",
    "            temp_continus_attr_seg_index = -1\n",
    "            for attr_index in range(len(attr_is_dispersed)):\n",
    "                if attr_is_dispersed[attr_index] == 1:  # 离散值\n",
    "                    uniques_attr, uniques_attr_counts = np.unique(\n",
    "                        self.data_x[:, attr_index], return_counts=True)\n",
    "                    if len(uniques_attr) == 1:\n",
    "                        continue\n",
    "                    for cur_attr_label in uniques_attr:\n",
    "                        cur_mask = (self.data_x[:, attr_index] == cur_attr_label)\n",
    "                        cur_not_mask = (self.data_x[:, attr_index] != cur_attr_label)\n",
    "                        cur_gini = (np.sum(cur_mask) * 1.0 / n_samples) * \\\n",
    "                                   self.get_gini(self.data_y[cur_mask], np.sum(cur_mask)) + \\\n",
    "                                   (np.sum(cur_not_mask) * 1.0 / n_samples) * \\\n",
    "                                   self.get_gini(self.data_y[cur_not_mask], np.sum(cur_not_mask))\n",
    "                        if temp_gini > cur_gini:\n",
    "                            temp_gini = cur_gini\n",
    "                            temp_attr_index = attr_index\n",
    "                            temp_attr_seg = np.array([cur_attr_label])\n",
    "\n",
    "                else:  # 连续值,需要寻找一个最优的二分点来分割数据，需要进行n_samples-1次尝试\n",
    "                    sort_index = np.argsort(self.data_x[:, attr_index])\n",
    "\n",
    "                    for i in range(n_samples - 1):\n",
    "                        temp_continus_seg_value = (data_x[sort_index[i], attr_index] + \\\n",
    "                                                   data_x[sort_index[i + 1], attr_index]) / 2.0\n",
    "                        cur_gini = ((i + 1) * 1.0 / n_samples) * \\\n",
    "                                   self.get_gini(data_y[sort_index[:i + 1]], i + 1) + \\\n",
    "                                   ((n_samples - i - 1) * 1.0 / n_samples) * \\\n",
    "                                   self.get_gini(data_y[sort_index[i + 1:]], n_samples - i - 1)\n",
    "                        if temp_gini > cur_gini:\n",
    "                            temp_gini = cur_gini\n",
    "                            temp_attr_index = attr_index\n",
    "                            temp_attr_seg = np.array([temp_continus_seg_value])\n",
    "                            temp_continus_attr_seg_index = i\n",
    "            if temp_gini == 1:\n",
    "                self.is_leaf = True\n",
    "                return\n",
    "            # 利用最优属性进行划分，并创造该节点的子节点，保存在self.next_nodes结构中\n",
    "            self.seg_attr_index = temp_attr_index  # 该节点的分割属性（轴）的下标\n",
    "            self.seg_attr_value = temp_attr_seg[0]\n",
    "\n",
    "            # 最优属性是离散值\n",
    "            if attr_is_dispersed[self.seg_attr_index] == 1:\n",
    "                cur_mask = (self.data_x[:, self.seg_attr_index] == self.seg_attr_value)\n",
    "                cur_not_mask = (self.data_x[:, self.seg_attr_index] != self.seg_attr_value)\n",
    "                self.next_nodes[0] = TreeNode(self.data_x[cur_mask],\n",
    "                                              self.data_y[cur_mask],\n",
    "                                              attr_is_dispersed)\n",
    "\n",
    "                self.next_nodes[1] = TreeNode(self.data_x[cur_not_mask],\n",
    "                                              self.data_y[cur_not_mask],\n",
    "                                              attr_is_dispersed)\n",
    "            else:  # 最优属性是连续值\n",
    "                sort_index = np.argsort(self.data_x[:, temp_attr_index])\n",
    "                # 不大于分割属性的子节点\n",
    "                self.next_nodes[0] = TreeNode(\n",
    "                    data_x[sort_index[:temp_continus_attr_seg_index + 1]],\n",
    "                    data_y[sort_index[:temp_continus_attr_seg_index + 1]],\n",
    "                    attr_is_dispersed)  # left\n",
    "                # 大于分割属性的子节点\n",
    "                self.next_nodes[1] = TreeNode(\n",
    "                    data_x[sort_index[temp_continus_attr_seg_index + 1:]],\n",
    "                    data_y[sort_index[temp_continus_attr_seg_index + 1:]],\n",
    "                    attr_is_dispersed)  # right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, train_x, train_y, attributes_classs=None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "\n",
    "        # 确定属性是连续/离散的,当属性中唯一值数量多于N/2时，认定为连续值\n",
    "        n_samples, n_features = self.train_x.shape\n",
    "        if attributes_classs is None:\n",
    "            attributes_classs = [0] * n_samples\n",
    "            for i in range(n_features):\n",
    "                uniques_i = np.unique(self.train_x[:, i])\n",
    "                if uniques_i * 3 > n_samples:\n",
    "                    attributes_classs[i] = 0\n",
    "        self.attributes_classs = attributes_classs\n",
    "        # 对离散属性、label做encoder处理\n",
    "        self.xLabelEncoders = []\n",
    "        for i in range(len(self.attributes_classs)):\n",
    "            if self.attributes_classs[i] == 1:  # 离散属性\n",
    "                cur_encoder = LabelEncoder()\n",
    "                cur_encoder.fit(self.train_x[:, i])\n",
    "                self.train_x[:, i] = cur_encoder.transform(self.train_x[:, i])\n",
    "                self.xLabelEncoders.append(cur_encoder)\n",
    "            else:\n",
    "                self.xLabelEncoders.append(None)\n",
    "        self.yLabelEncoders = LabelEncoder()\n",
    "        self.yLabelEncoders.fit(train_y)\n",
    "        self.train_y = self.yLabelEncoders.transform(self.train_y)\n",
    "        self.root = None  # 根节点\n",
    "\n",
    "    def train(self):\n",
    "        self.root = TreeNode(self.train_x, self.train_y, self.attributes_classs)\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        # 从根节点开始遍历树形结构，\n",
    "        if self.root is None:\n",
    "            raise RuntimeError(\"value is None, error\")\n",
    "        # 首先将测试数据集的离散属性LAbelencoder,然后进行预测\n",
    "        for (i, x_label_encoder) in enumerate(self.xLabelEncoders):\n",
    "            if x_label_encoder is not None:\n",
    "                test_x[:, i] = x_label_encoder.transform(test_x[:, i],)\n",
    "        n_samples, _ = test_x.shape\n",
    "        pre = np.zeros(n_samples)\n",
    "        for i in xrange(n_samples):\n",
    "            cur_node = self.root\n",
    "            while cur_node.is_leaf is False:\n",
    "                cur_attr_index = cur_node.seg_attr_index  # 分割属性下标\n",
    "                if self.attributes_classs[cur_attr_index] == 1:  # 离散属性\n",
    "                    if test_x[i][cur_attr_index] == cur_node.seg_attr_value:\n",
    "                        cur_node = cur_node.next_nodes[0]\n",
    "                    else:\n",
    "                        cur_node = cur_node.next_nodes[1]\n",
    "                else:  # 连续属性\n",
    "                    if test_x[i][cur_attr_index] <= cur_node.seg_attr_value:\n",
    "                        cur_node = cur_node.next_nodes[0]\n",
    "                    else:\n",
    "                        cur_node = cur_node.next_nodes[1]\n",
    "            # 找到了叶子节点，可以展开预测动作了，基本的投票原则\n",
    "            pre[i] = np.argmax(np.bincount(cur_node.data_y))\n",
    "        pre = pre.astype(np.int)\n",
    "        return self.yLabelEncoders.inverse_transform(pre)  # 反向转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遍历决策树\n",
    "- 作为绘制决策树的基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树的遍历，以字典的形式返回\n",
    "def list_dt(root, attr_is_dispersed):\n",
    "    if root.is_leaf is True:\n",
    "        return np.argmax(np.bincount(root.data_y)) # 返回预测标签\n",
    "    else:\n",
    "        temp_dic = {}\n",
    "        if attr_is_dispersed[root.seg_attr_index] == 1:\n",
    "            temp_dic[str(root.seg_attr_index)+' is '+str(root.seg_attr_value)] = list_dt(root.next_nodes[0],\n",
    "                                                                                 attr_is_dispersed)\n",
    "            temp_dic[str(root.seg_attr_index)+' is not '+str(root.seg_attr_value)] = list_dt(root.next_nodes[1],\n",
    "                                                                                 attr_is_dispersed)\n",
    "        else:\n",
    "            temp_dic[str(root.seg_attr_index)+' <= ' + str(root.seg_attr_value)] = list_dt(root.next_nodes[0],\n",
    "                                                                                         attr_is_dispersed)\n",
    "            temp_dic[str(root.seg_attr_index)+' > ' + str(root.seg_attr_value)] = list_dt(root.next_nodes[1],\n",
    "                                                                                        attr_is_dispersed)\n",
    "        return temp_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path = '../data/heart.csv'):\n",
    "    weather = pd.read_csv(path,sep=',')\n",
    "    data = weather.values\n",
    "    data_x = data[:,:-1]\n",
    "    data_y = data[:, -1]\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(train_x[:, [1,5,8,12]], train_y, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y = dt.predict(test_x[:,[1,5,8,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72131147540983609"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pre_y == test_y)*1.0 / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_y = dt.predict(train_x[:, [1,5,8,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80578512396694213"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pre_train_y == train_y)*1.0 / train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3 is 2.0': {'2 is 0.0': {'0 is 0.0': {'1 is 0.0': 1, '1 is not 0.0': 1},\n",
       "   '0 is not 0.0': {'1 is 0.0': 1, '1 is not 0.0': 1}},\n",
       "  '2 is not 0.0': {'0 is 0.0': {'1 is 0.0': 1, '1 is not 0.0': 1},\n",
       "   '0 is not 0.0': {'1 is 0.0': 0, '1 is not 0.0': 0}}},\n",
       " '3 is not 2.0': {'2 is 0.0': {'1 is 0.0': {'3 is 3.0': {'0 is 0.0': 0,\n",
       "     '0 is not 0.0': 0},\n",
       "    '3 is not 3.0': {'0 is 0.0': 1, '0 is not 0.0': 1}},\n",
       "   '1 is not 0.0': {'3 is 1.0': 0, '3 is not 1.0': 1}},\n",
       "  '2 is not 0.0': {'0 is 0.0': 0,\n",
       "   '0 is not 0.0': {'1 is 0.0': {'3 is 1.0': 0, '3 is not 1.0': 0},\n",
       "    '1 is not 0.0': 0}}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dt(dt.root, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_dt = DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_dt.fit(train_x[:,[1,5,8,12]], train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_pre = sk_dt.predict(test_x[:,[1,5,8,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72131147541\n"
     ]
    }
   ],
   "source": [
    "print np.sum(sk_pre == test_y)*1.0 / test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_train_pre = sk_dt.predict(train_x[:,[1,5,8,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805785123967\n"
     ]
    }
   ],
   "source": [
    "print np.sum(sk_train_pre == train_y)*1.0 / train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
