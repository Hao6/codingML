{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax回归\n",
    "- 多分类任务的逻辑回归版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(object):\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, is_regularization = None, lam=0.1,\n",
    "                verbose = False):\n",
    "        \"\"\"\n",
    "        :type learning_rate: float, 学习率\n",
    "        :type epochs: int, 迭代次数\n",
    "        :type is_regularization: int, None: 不使用正则化，l1: L1正则化，l2: L2正则化\n",
    "        :type lam: 正则化项的系数\n",
    "        \"\"\"\n",
    "        self.alpha = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.is_regularization = is_regularization\n",
    "        self.lam = lam\n",
    "        self.theta = None\n",
    "        self.b = None\n",
    "        self.verbose = verbose\n",
    "        self.y_one_hot = OneHotEncoder()\n",
    "    def train(self, train_x, train_y):\n",
    "        m , n = train_x.shape\n",
    "        if len(train_y.shape) == 1:\n",
    "            train_y = train_y.reshape(-1, 1)\n",
    "        self.y_one_hot.fit(train_y)\n",
    "        train_y = self.y_one_hot.transform(train_y).A\n",
    "        _, nn = train_y.shape\n",
    "        self.theta = np.random.randn(nn ,n)\n",
    "        self.b = np.random.randn(nn)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            pre_y = self.predict(train_x)\n",
    "#             print pre_y.shape, train_y.shape\n",
    "            d_theta = np.dot((pre_y - train_y).T, train_x)\n",
    "            d_b     = np.mean(pre_y - train_y, axis=0)\n",
    "            assert d_b.shape == self.b.shape and d_theta.shape == self.theta.shape\n",
    "#             print d_theta.shape\n",
    "            # L1 正则\n",
    "            if self.is_regularization == 'l1':\n",
    "                d_l1 = np.ones_like(self.theta)\n",
    "                d_l1[self.theta < 0] = -1\n",
    "                d_theta += self.lam * d_l1\n",
    "            # L2 正则\n",
    "            elif self.is_regularization == 'l2':\n",
    "                d_theta += self.lam * self.theta\n",
    "            \n",
    "            self.theta -= self.alpha * d_theta\n",
    "            self.b     -= self.alpha * d_b\n",
    "            if self.verbose is True and (i+1)%(m/10) == 0:\n",
    "                print 'the %d train' % (i)\n",
    "    \n",
    "    def fit(self, train_x, train_y):\n",
    "        self.train(train_x, train_y)\n",
    "        \n",
    "    def predict(self, test_x):\n",
    "        return self.softmax(np.dot(test_x, self.theta.T)+self.b)\n",
    "        \n",
    "    def output(self, test_x):\n",
    "        pre = self.predict(test_x) # M * S,需要转化为one-hot编码，最大的编码为1，其余的编码为0\n",
    "        out = np.argmax(pre, axis = 1)\n",
    "        return out\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = iris_data.data\n",
    "y_data = iris_data.target\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)\n",
    "assert x_train.shape[1] == x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = SoftmaxRegression(learning_rate=0.001, epochs=1000, is_regularization = None, \n",
    "                       lam=0.1,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y = sr.output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0, 12]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
