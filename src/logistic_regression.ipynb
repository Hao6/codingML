{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置\n",
    "- X, 样本数据, shape=(m,n),type:np.ndarray()\n",
    "- y, 标签数据, shape=(m,1),type:np.ndarray()\n",
    "- theta, 权重, shape=(1,n),type:np.ndarray()\n",
    "- b, 偏差，标量, type:float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, is_regularization = None, lam=0.1,\n",
    "                verbose = False):\n",
    "        \"\"\"\n",
    "        :type learning_rate: float, 学习率\n",
    "        :type epochs: int, 迭代次数\n",
    "        :type is_regularization: int, None: 不使用正则化，l1: L1正则化，l2: L2正则化\n",
    "        :type lam: 正则化项的系数\n",
    "        \"\"\"\n",
    "        self.alpha = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.is_regularization = is_regularization\n",
    "        self.lam = lam\n",
    "        self.theta = None\n",
    "        self.b = None\n",
    "        self.verbose = verbose\n",
    "    def train(self, train_x, train_y):\n",
    "        m , n = train_x.shape\n",
    "        if len(train_y.shape) == 1:\n",
    "            train_y = train_y.reshape(-1, 1)\n",
    "        self.theta = np.random.randn(1 ,n)\n",
    "        self.b = np.random.randn()\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            pre_y = self.predict(train_x)\n",
    "#             print pre_y.shape, train_y.shape\n",
    "            d_theta = np.mean((pre_y - train_y)*train_x, axis=0).reshape(*self.theta.shape)\n",
    "            d_b     = np.mean(pre_y - train_y, axis=0)\n",
    "#             print d_theta.shape\n",
    "            # L1 正则\n",
    "            if self.is_regularization == 'l1':\n",
    "                d_l1 = np.ones_like(self.theta)\n",
    "                d_l1[self.theta < 0] = -1\n",
    "                d_theta += self.lam * d_l1\n",
    "            # L2 正则\n",
    "            elif self.is_regularization == 'l2':\n",
    "                d_theta += self.lam * self.theta\n",
    "            \n",
    "            self.theta -= self.alpha * d_theta\n",
    "            self.b     -= self.alpha * d_b\n",
    "            if self.verbose is True and (i+1)%(m/10) == 0:\n",
    "                print 'the %d train' % (i)\n",
    "    \n",
    "    def fit(self, train_x, train_y):\n",
    "        self.train(train_x, train_y)\n",
    "        \n",
    "    def predict(self, test_x):\n",
    "        return self.sigmoid(np.dot(test_x, self.theta.T)+self.b)\n",
    "        \n",
    "    def output(self, test_x):\n",
    "        return (self.sigmoid(np.dot(test_x, self.theta.T)+self.b) > 0.5).astype(int)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (np.exp(-x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    digits = datasets.load_digits()\n",
    "    X, y = digits.data, digits.target\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # classify small against large digits\n",
    "    y = (y > 4).astype(np.int)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X, y):\n",
    "    for i, lam in enumerate((3, 6, 9)):\n",
    "        # turn down tolerance for short training time\n",
    "        clf_l1_LR = LogisticRegression(learning_rate=0.2, epochs=11000, \n",
    "                                       is_regularization='l1', lam=lam, verbose=False)\n",
    "        clf_l2_LR = LogisticRegression(learning_rate=0.2, epochs=11000, \n",
    "                                       is_regularization='l2', lam=lam, verbose=False)\n",
    "        clf_l1_LR.fit(X, y)\n",
    "        clf_l2_LR.fit(X, y)\n",
    "\n",
    "        coef_l1_LR = clf_l1_LR.theta.ravel()\n",
    "        coef_l2_LR = clf_l2_LR.theta.ravel()\n",
    "\n",
    "        # coef_l1_LR contains zeros due to the\n",
    "        # L1 sparsity inducing norm\n",
    "\n",
    "        sparsity_l1_LR = np.sum(coef_l1_LR == 0)\n",
    "        sparsity_l2_LR = np.sum(coef_l2_LR == 0)\n",
    "        \n",
    "        clf_l1_pre_y = clf_l1_LR.output(X)\n",
    "        clf_l2_pre_y = clf_l2_LR.output(X)\n",
    "\n",
    "        print(\"lam=%f\" % lam)\n",
    "        print(\"Sparsity with L1 penalty: %d\" % sparsity_l1_LR)\n",
    "        print(\"score with L1 penalty: %f\" % accuracy_score(clf_l1_pre_y, y))\n",
    "        print(\"Sparsity with L2 penalty: %d\" % sparsity_l2_LR)\n",
    "        print(\"score with L2 penalty: %f\" % accuracy_score(clf_l2_pre_y, y)) \n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        l1_plot = plt.subplot(3, 2, 2 * i + 1)\n",
    "        l2_plot = plt.subplot(3, 2, 2 * (i + 1))\n",
    "        if i == 0:\n",
    "            l1_plot.set_title(\"L1 penalty\")\n",
    "            l2_plot.set_title(\"L2 penalty\")\n",
    "\n",
    "        l1_plot.imshow(np.abs(coef_l1_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                       cmap='binary', vmax=1, vmin=0)\n",
    "        l2_plot.imshow(np.abs(coef_l2_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                       cmap='binary', vmax=1, vmin=0)\n",
    "        plt.text(-8, 3, \"lam = %f\" % lam)\n",
    "\n",
    "        l1_plot.set_xticks(())\n",
    "        l1_plot.set_yticks(())\n",
    "        l2_plot.set_xticks(())\n",
    "        l2_plot.set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam=3.000000\n",
      "Sparsity with L1 penalty: 0\n",
      "score with L1 penalty: 0.514747\n",
      "Sparsity with L2 penalty: 3\n",
      "score with L2 penalty: 0.847524\n",
      "lam=6.000000\n",
      "Sparsity with L1 penalty: 0\n",
      "score with L1 penalty: 0.513077\n",
      "Sparsity with L2 penalty: 3\n",
      "score with L2 penalty: 0.835838\n",
      "lam=9.000000\n",
      "Sparsity with L1 penalty: 0\n",
      "score with L1 penalty: 0.671119\n",
      "Sparsity with L2 penalty: 0\n",
      "score with L2 penalty: 0.454090\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAACFCAYAAACgwXodAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACJtJREFUeJzt3X+oXmUBB/Dvc7fLCqQ2uTZCh5OSNchQHLqgLCvMDHKGFZY4IxlJUPSXMcJBSSSIUCIihuRQqDRWBqXIFIVs0hTRBM2BumRuav5IGfPH7tMf96zWvLP7Pvfu6qOfD7zc8573fM9z7vvH++Wc98dTaq0BAPo09lYfAADQTpEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0bOEoG5dSmn4GbtGiRS2xTExMNOV27drVlHv99debckuXLm3KvfTSS0253bt3N+WSPFtrPaI1DPRlYmKiLl++/K0+jLed+f5F01JKU+7ee++d0Wv2SEXeatmyZU25devWNeUuv/zyptzOnTubcmvXrm3K3X777U25rVu3NuWSPNEaBPqzfPny2bxezJv5LtbWk7ZWCxe2Ve3Y2NiMXrNdWgeAjilyAOiYIgeAjilyAOiYIgeAjilyAOiYIgeAjilyAOiYIgeAjilyAOiYIgeAjilyAOjYSL/kvnLlymzcuHHkQZ54om2ujrPPPrspd8oppzTlWidNueWWW5py55xzTlPuyiuvbMqdfPLJTTmAmdi7d29TbsGCBU251157rSk3Pj7elGv9/1pnP5spZ+QA0DFFDgAdU+QA0DFFDgAdU+QA0DFFDgAdU+QA0DFFDgAdU+QA0DFFDgAdU+QA0DFFDgAdU+QA0LGRZj/btm1b1qxZM/IgF1988ciZ2bjrrruacnfccUdT7tRTT23KPfDAA025K664oikHcCjVWptyk5OT8zpea651lrZDzRk5AHRMkQNAxxQ5AHRMkQNAxxQ5AHRMkQNAxxQ5AHRMkQNAxxQ5AHRMkQNAxxQ5AHRMkQNAxxQ5AHRspNnPVqxYkU2bNo08SOusYkuWLGnK3XjjjU25yy67rCn34osvNuWuv/76ptz27dubcjDXSikv11oPe4uPoSS5JMlXkuxNclWt9efTbLc2yQ+Hu5fUWq8b1p+Y5JdJ3pvkj0m+V2utpZTDk/w6yfIkjyf5aq31+WG8nyU5I8nuJOfXWu9rGWPunoW51XpoU0/N6Pbu3duUGx8fb8q1mu/nZaackQO9Oz/JsiQfqbWuTPKrAzcYSnlDkpOTnJRkQyll35nCVUnWJTl2uJ0+rP9Bks211mOTbB7uJ8kX9tt23ZBvHQNmTZEDs1ZKOayUsrmUcl8p5cFSypnD+uWllIdLKb8opfytlHJDKeVzpZQ/l1IeLaWcNAfDX5jkR7XWySSptT49zTafT3JbrfW5WuvzSW5Lcnop5YNJ3ldr/ctwhrwxyZohc2aS64bl6w5Yv7FO2ZJk8bCfljFg1ka6tA5wEHuSnFVr/VcpZSLJllLKzcNjH87UZe91Sf6a5OtJPpHkS0nW54BSK6WsyNQl7el8utb6wgHrPpTka6WUs5I8k+S7tdZHD9jmyCT/2O/+k8O6I4flA9cnydJa61NJUmt9qpTygRnsa9QxYNYUOTAXSpKflFJOSTKZqaJaOjz2WK31wSQppTyUqcvVtZTyYKbef/4ftdZHkhw/wtiLkuypta4qpXw5ybVJPjnN8b1hqDdZ/2ZG3VfLGDBjLq0Dc+EbSY5IcmKt9fgku5K8Z3jslf22m9zv/mSmOZkopawopdx/kNviacZ+Mslvh+VNST52kG2W7Xf/qCQ7hvVHTbM+SXYNl8Uz/N13yf7N9jXqGDBrihyYC+9P8nSt9bVSyqlJjm7dUa31kVrr8Qe5HXhZPUl+l+Qzw/Knkvx9mm1uTXJaKWXJ8AG005LcOlw6f6mUsnr4NPp5SX4/ZG5OsnZYXnvA+vPKlNVJXhz20zIGzJpL68BcuCHJH0opW5Pcn+TheRz7p0luKKV8P8nLSS5IklLKqiTfrrVeUGt9rpTy40y9R59MfTjuuWH5wvz3q2F/Gm779vubUsq3kmzP1Pv8ydTXx85Isi1TXz/7ZpI0jgGzpsiBZvu+Q15rfTbJxw+y2Uf32/78/ZYf3/+xWRzDC0m+OM36rRlKfbh/babeP59uuzccR631n0k+O836muQ7BzmWkcaAueDSOgB0TJEDQMcUOQB0TJEDQMcUOQB0bKRPre/cuTOXXnrpyIPcc889I2eS9plmWmdb27BhQ1Nu6dKl/3+jaezZs6cpd/XVVzflAGaidTaysbF39rnhoZ7FrNU7+1kHgHc4RQ4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANCxkWY/O/zww3PuueeOPMg111wzciZJlixZ0pS78847m3InnHBCU+6iiy5qym3btq0pd/fddzflgHef1lkkW7TOftaaa/3fWmcxm5ycnNfxZsoZOQB0TJEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0TJEDQMcUOQB0rIwye0wppWmqmeOOO64llhUrVjTlbrrppqbcY4891pTbsWNHU+6VV15pyq1fv74pt2XLlntrrauawkB3Vq1aVbdu3Tpybr5nFWsd79VXX23KLVw40sSf/9E6S1ursbGxGb1mOyMHgI4pcgDomCIHgI4pcgDomCIHgI4pcgDomCIHgI4pcgDomCIHgI4pcgDomCIHgI4pcgDomCIHgI6NNAXM+Ph4JiYmRh5k8eLFI2eS9lnMVq9e3ZQ75phjmnIPPfRQU27z5s1NuZUrVzbltmzZ0pQD3l1aZzGbbwsWLGjKtc5i1jpLW2tuppyRA0DHFDkAdEyRA0DHFDkAdEyRA0DHFDkAdEyRA0DHFDkAdEyRA0DHFDkAdEyRA0DHFDkAdEyRA0DHyiizspRSnknyxKE7HA6xo2utR7zVBwHMD6/Z3ZvRa/ZIRQ4AvL24tA4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANAxRQ4AHVPkANAxRQ4AHfs38nBn4RWWkrMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logisticRegression(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现一个one-vs-all的多类别分类器 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def load_data(path = \"../data/mnist\", kind = 'train', one_hot = True, normals = True):\n",
    "    images, labels = load_mnist(path, kind=kind)\n",
    "    if normals == True:\n",
    "        images = images / 255.0\n",
    "    if one_hot == True:\n",
    "        labels_onehot = np.zeros((labels.shape[0], np.unique(labels).shape[0]))\n",
    "        for i in range(labels_onehot.shape[0]):\n",
    "            labels_onehot[i][labels[i]] = 1\n",
    "        labels = labels_onehot\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(train_x, train_y, test_x, test_y):\n",
    "    # Turn up tolerance for faster convergence\n",
    "    \n",
    "    clf = LogisticRegression(learning_rate=0.01, epochs=1000, \n",
    "                             is_regularization='l1', lam=0.1)\n",
    "    clf.fit(train_x, train_y)\n",
    "    sparsity = np.mean(clf.theta == 0) * 100\n",
    "    pre_y = clf.predict(test_x)\n",
    "    score = clf.score(pre_y, test_y)\n",
    "    # print('Best C % .4f' % clf.C_)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "    print(\"Test score with L1 penalty: %.4f\" % score)\n",
    "\n",
    "    coef = clf.theta.copy()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    scale = np.abs(coef).max()\n",
    "    for i in range(10):\n",
    "        l1_plot = plt.subplot(2, 5, i + 1)\n",
    "        l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
    "                       cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
    "        l1_plot.set_xticks(())\n",
    "        l1_plot.set_yticks(())\n",
    "        l1_plot.set_xlabel('Class %i' % i)\n",
    "    plt.suptitle('Classification vector for...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data(kind='train')\n",
    "test_x, test_y = load_data(kind='t10k')\n",
    "print train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
