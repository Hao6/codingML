{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART回归树\n",
    "- 树型回归是一种区域回归（相对于线性回归）\n",
    "- cart算法被用来生成回归树时采用平方误差最小作为属性划分依据\n",
    "- 算法停止条件是训练数据小于某种程度、平方误差小于某种程度、属性数据完全一致等情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    # 根据标签序列计算gini指数\n",
    "    def get_square_error(self, labels_list):\n",
    "        \"\"\"\n",
    "        :labels_list, ndarray, 标签列表、数组\n",
    "        :n_samples, int, 总的类别数\n",
    "        计算信息熵\n",
    "        \"\"\"\n",
    "        labels_mean = np.mean(labels_list)\n",
    "        return np.sum(np.square(labels_list - labels_mean))\n",
    "\n",
    "    def __init__(self, data_x, data_y, attr_is_dispersed, square_error_threshold):\n",
    "        '''\n",
    "        :data_x: ndarray, 标签化的数据集x\n",
    "        :data_y: ndarray, 标签化的数据集y\n",
    "        :attr_is_dispersed, ndarray, 属性是否为离散的，例如[1,0,1,0,1],则表示下标0、2、4的属性是离散的，\n",
    "        '''\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.next_nodes = {}  # 存储子节点\n",
    "        self.is_leaf = None\n",
    "        self.seg_attr_index = -1  # 在该节点选择的分割属性\n",
    "        self.seg_attr_value = -1  # 分割属性值，返回属性分割值\n",
    "\n",
    "        n_samples, n_features = data_x.shape\n",
    "        # 当前节点数据数不大于1、数据标签y全部一致的情况下，认定为子节点\n",
    "        square_error = self.get_square_error(self.data_y)\n",
    "        if n_samples <= 1 or square_error < square_error_threshold:\n",
    "            self.is_leaf = True\n",
    "        else:  # 非叶子节点\n",
    "            #             gain = self.get_Information_entropy(self.data_y, n_samples)  # 熵\n",
    "            self.is_leaf = False\n",
    "            # 根据可用分割属性segmentation_attr，以及属性离散/连续记录表attr_is_dispersed来确定最优\n",
    "            temp_se = np.inf  # 保存最小的平方误差\n",
    "            temp_attr_index = -1  # 保存按哪个属性分割可以得到最小的平方误差\n",
    "\n",
    "            # 返回包含分割点的属性值\n",
    "            temp_attr_seg = None\n",
    "            # 如果优属性是连续的，则返回升序属性序列的分割点下标，方便后续计算\n",
    "            temp_continus_attr_seg_index = -1\n",
    "            for attr_index in range(len(attr_is_dispersed)):\n",
    "                if attr_is_dispersed[attr_index] == 1:  # 离散值\n",
    "                    uniques_attr, uniques_attr_counts = np.unique(\n",
    "                        self.data_x[:, attr_index], return_counts=True)\n",
    "                    if len(uniques_attr) == 1:\n",
    "                        continue\n",
    "                    for cur_attr_label in uniques_attr:\n",
    "                        cur_mask = (self.data_x[:, attr_index] == cur_attr_label)\n",
    "                        cur_not_mask = (self.data_x[:, attr_index] != cur_attr_label)\n",
    "                        cur_se = self.get_square_error(self.data_y[cur_mask]) + \\\n",
    "                                   self.get_square_error(self.data_y[cur_not_mask])\n",
    "                        if temp_se > cur_se:\n",
    "                            temp_se = cur_se\n",
    "                            temp_attr_index = attr_index\n",
    "                            temp_attr_seg = np.array([cur_attr_label])\n",
    "\n",
    "                else:  # 连续值,需要寻找一个最优的二分点来分割数据，需要进行n_samples-1次尝试\n",
    "                    sort_index = np.argsort(self.data_x[:, attr_index])\n",
    "\n",
    "                    for i in range(n_samples - 1):\n",
    "                        temp_continus_seg_value = (data_x[sort_index[i], attr_index] + \\\n",
    "                                                   data_x[sort_index[i + 1], attr_index]) / 2.0\n",
    "                        cur_se = self.get_square_error(data_y[sort_index[:i + 1]]) + \\\n",
    "                                   self.get_square_error(data_y[sort_index[i + 1:]])\n",
    "                        if temp_se > cur_se:\n",
    "                            temp_se = cur_se\n",
    "                            temp_attr_index = attr_index\n",
    "                            temp_attr_seg = np.array([temp_continus_seg_value])\n",
    "                            temp_continus_attr_seg_index = i\n",
    "            if temp_se == np.inf:\n",
    "                self.is_leaf = True\n",
    "                return\n",
    "            # 利用最优属性进行划分，并创造该节点的子节点，保存在self.next_nodes结构中\n",
    "            self.seg_attr_index = temp_attr_index  # 该节点的分割属性（轴）的下标\n",
    "            self.seg_attr_value = temp_attr_seg[0]\n",
    "\n",
    "            # 最优属性是离散值\n",
    "            if attr_is_dispersed[self.seg_attr_index] == 1:\n",
    "                cur_mask = (self.data_x[:, self.seg_attr_index] == self.seg_attr_value)\n",
    "                cur_not_mask = (self.data_x[:, self.seg_attr_index] != self.seg_attr_value)\n",
    "                self.next_nodes[0] = TreeNode(self.data_x[cur_mask],\n",
    "                                              self.data_y[cur_mask],\n",
    "                                              attr_is_dispersed,\n",
    "                                             square_error_threshold)\n",
    "\n",
    "                self.next_nodes[1] = TreeNode(self.data_x[cur_not_mask],\n",
    "                                              self.data_y[cur_not_mask],\n",
    "                                              attr_is_dispersed,\n",
    "                                             square_error_threshold)\n",
    "            else:  # 最优属性是连续值\n",
    "                sort_index = np.argsort(self.data_x[:, temp_attr_index])\n",
    "                # 不大于分割属性的子节点\n",
    "                self.next_nodes[0] = TreeNode(\n",
    "                    data_x[sort_index[:temp_continus_attr_seg_index + 1]],\n",
    "                    data_y[sort_index[:temp_continus_attr_seg_index + 1]],\n",
    "                    attr_is_dispersed,\n",
    "                    square_error_threshold)  # left\n",
    "                # 大于分割属性的子节点\n",
    "                self.next_nodes[1] = TreeNode(\n",
    "                    data_x[sort_index[temp_continus_attr_seg_index + 1:]],\n",
    "                    data_y[sort_index[temp_continus_attr_seg_index + 1:]],\n",
    "                    attr_is_dispersed,\n",
    "                    square_error_threshold)  # right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, train_x, train_y, attributes_classs=None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "\n",
    "        # 确定属性是连续/离散的,当属性中唯一值数量多于N/2时，认定为连续值\n",
    "        n_samples, n_features = self.train_x.shape\n",
    "        if attributes_classs is None:\n",
    "            attributes_classs = [0] * n_samples\n",
    "            for i in range(n_features):\n",
    "                uniques_i = np.unique(self.train_x[:, i])\n",
    "                if uniques_i * 3 > n_samples:\n",
    "                    attributes_classs[i] = 0\n",
    "        self.attributes_classs = attributes_classs\n",
    "        # 对离散属性、label做encoder处理\n",
    "        self.xLabelEncoders = []\n",
    "        for i in range(len(self.attributes_classs)):\n",
    "            if self.attributes_classs[i] == 1:  # 离散属性\n",
    "                cur_encoder = LabelEncoder()\n",
    "                cur_encoder.fit(self.train_x[:, i])\n",
    "                self.train_x[:, i] = cur_encoder.transform(self.train_x[:, i])\n",
    "                self.xLabelEncoders.append(cur_encoder)\n",
    "            else:\n",
    "                self.xLabelEncoders.append(None)\n",
    "        self.root = None  # 根节点\n",
    "\n",
    "    def train(self, square_error_threshold=0.8):\n",
    "        self.root = TreeNode(self.train_x, self.train_y, self.attributes_classs, \n",
    "                             square_error_threshold)\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        # 从根节点开始遍历树形结构，\n",
    "        if self.root is None:\n",
    "            raise RuntimeError(\"value is None, error\")\n",
    "        # 首先将测试数据集的离散属性LAbelencoder,然后进行预测\n",
    "        for (i, x_label_encoder) in enumerate(self.xLabelEncoders):\n",
    "            if x_label_encoder is not None:\n",
    "                test_x[:, i] = x_label_encoder.transform(test_x[:, i],)\n",
    "        n_samples, _ = test_x.shape\n",
    "        pre = np.zeros(n_samples)\n",
    "        for i in xrange(n_samples):\n",
    "            cur_node = self.root\n",
    "            while cur_node.is_leaf is False:\n",
    "                cur_attr_index = cur_node.seg_attr_index  # 分割属性下标\n",
    "                if self.attributes_classs[cur_attr_index] == 1:  # 离散属性\n",
    "                    if test_x[i][cur_attr_index] == cur_node.seg_attr_value:\n",
    "                        cur_node = cur_node.next_nodes[0]\n",
    "                    else:\n",
    "                        cur_node = cur_node.next_nodes[1]\n",
    "                else:  # 连续属性\n",
    "                    if test_x[i][cur_attr_index] <= cur_node.seg_attr_value:\n",
    "                        cur_node = cur_node.next_nodes[0]\n",
    "                    else:\n",
    "                        cur_node = cur_node.next_nodes[1]\n",
    "            # 找到了叶子节点，可以展开预测动作了，取平均值\n",
    "            pre[i] = np.mean(cur_node.data_y)\n",
    "        return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path='../data/StudentsPerformance.csv'):\n",
    "    sp = pd.read_csv(path, sep=',')\n",
    "    data = sp.values\n",
    "    data_x = data[:,:-1]\n",
    "    data_y = data[:,-1]\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'group C', 'some college', 'standard', 'none', 59, 41], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_classs = [1, 1, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(train_x, train_y, attributes_classs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.train(square_error_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y = dt.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.21691958918\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(np.mean(np.square(pre_y - test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_regre = DecisionTreeRegressor(criterion='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regre.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pre_y = dt_regre.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.58077055611\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(np.mean(np.square(sklearn_pre_y - test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
