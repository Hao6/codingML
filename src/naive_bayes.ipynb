{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "- 采用积极学习\n",
    "- 训练过程实际上就是构建一个三级字典，存储对应的先验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    # 为了方便处理离散数据数据的不同属性值，分别进行编码\n",
    "    def __init__(self, alpha=1):\n",
    "        self.xEncoders = []\n",
    "        self.yEncoder = None\n",
    "        self.is_dispersed = None\n",
    "        self.alpha = alpha  # 平滑系数，=1,拉普拉斯平滑， =0 ，无平滑， 0<alpha<1,其他平滑\n",
    "        # 用来保存先验概率与似然的字典结构\n",
    "        self.y_labels_count = None\n",
    "        self.x_labels_count = None\n",
    "\n",
    "    def __statistic(self, data, is_dispersed=True):\n",
    "        res = {}\n",
    "        if is_dispersed is True:  # 数据是离散的\n",
    "            labels_count = np.bincount(data.astype(np.int))\n",
    "            labels = np.nonzero(labels_count)[0]\n",
    "            for label in labels:\n",
    "                res[label] = labels_count[label]\n",
    "            res['sum'] = data.shape[0]\n",
    "            res['labels'] = len(labels)\n",
    "        else:  # 数据是连续的\n",
    "            res['mean'] = np.mean(data)\n",
    "            res['std'] = np.std(data)\n",
    "        return res\n",
    "\n",
    "    def train(self, train_x, train_y, is_dispersed=None):\n",
    "        self.is_dispersed = is_dispersed  # 判断属性是否是离散的，方便编码与计算先验概率\n",
    "        m, n = train_x.shape\n",
    "        for i in range(n):\n",
    "            if self.is_dispersed[i] is True:\n",
    "                cur_le = LabelEncoder()\n",
    "                cur_le.fit(train_x[:, i])\n",
    "                train_x[:, i] = cur_le.transform(train_x[:, i])\n",
    "                self.xEncoders.append(cur_le)\n",
    "            else:\n",
    "                self.xEncoders.append(None)\n",
    "        cur_le = LabelEncoder()\n",
    "        cur_le.fit(train_y)\n",
    "        train_y = cur_le.transform(train_y)\n",
    "        self.yEncoder = cur_le\n",
    "\n",
    "        # y标签的每种属性值的value_count\n",
    "        y_labels_count = self.__statistic(train_y, is_dispersed=True)\n",
    "        x_labels_count = {}\n",
    "        for key in y_labels_count.keys()[:-2]:\n",
    "            x_labels_count[key] = {}\n",
    "            cur_train_x = train_x[train_y == key]\n",
    "            for i in range(n):\n",
    "                x_labels_count[key][i] = self.__statistic(cur_train_x[:, i],\n",
    "                                                          self.is_dispersed[i])\n",
    "        self.y_labels_count = y_labels_count\n",
    "        self.x_labels_count = x_labels_count\n",
    "\n",
    "    def fit(self, train_x, train_y, is_dispersed=None):\n",
    "        self.train(train_x, train_y, is_dispersed)\n",
    "\n",
    "    def __calProbability(self, labels_count_dic, labels_value, is_dispersed=True):\n",
    "        if is_dispersed is True:  # 离散属性，计算概率\n",
    "            if labels_value not in labels_count_dic:\n",
    "                return self.alpha / (labels_count_dic['sum'] +\n",
    "                                     (len(labels_count_dic) - 1) * self.alpha)\n",
    "            else:\n",
    "                return (labels_count_dic[labels_value] +\n",
    "                        self.alpha) / (labels_count_dic['sum'] +\n",
    "                                       (len(labels_count_dic) - 1) * self.alpha)\n",
    "        else:  # 连续属性属性，计算概率\n",
    "            cur_mean = labels_count_dic['mean']\n",
    "            cur_std = labels_count_dic['std']\n",
    "            return (1 / (np.sqrt(2 * np.pi) * cur_std)) * \\\n",
    "                   np.exp(-np.square(labels_value - cur_mean) / (2 * cur_std ** 2))\n",
    "\n",
    "    def predict(self, x):\n",
    "        m, n = x.shape\n",
    "        x = np.copy(x)\n",
    "        pre_y = np.zeros(m)\n",
    "        for i in range(n):\n",
    "            if self.xEncoders[i] is not None:\n",
    "                x[:, i] = self.xEncoders[i].transform(x[:, i])\n",
    "        # 比较后验概率的相对大小\n",
    "        for i in range(m):\n",
    "            max_post_probability = 0\n",
    "            pre_label = -1\n",
    "            for y_label in self.y_labels_count.keys()[:-2]:\n",
    "                y_label_pro = self.__calProbability(self.y_labels_count, y_label)\n",
    "                temp_post_probability = 1\n",
    "                temp_post_probability *= y_label_pro\n",
    "                for j in range(n):\n",
    "                    temp_post_probability *= self.__calProbability(\n",
    "                        self.x_labels_count[y_label][j], x[i][j],\n",
    "                        is_dispersed=self.is_dispersed[j])\n",
    "                if temp_post_probability > max_post_probability:\n",
    "                    max_post_probability = temp_post_probability\n",
    "                    pre_label = y_label\n",
    "            pre_y[i] = pre_label\n",
    "        return self.yEncoder.transform(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path = '../data/heart.csv'):\n",
    "    heart_data = pd.read_csv(path).values\n",
    "    y = heart_data[:, -1]\n",
    "    x = heart_data[:, :-1]\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)\n",
    "    assert train_x.shape[1] == test_x.shape[1]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.10000000e+01,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.26000000e+02,   3.06000000e+02,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.63000000e+02,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00],\n",
       "       [  4.80000000e+01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.30000000e+02,   2.45000000e+02,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.80000000e+02,   0.00000000e+00,\n",
       "          2.00000000e-01,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00],\n",
       "       [  5.40000000e+01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.08000000e+02,   3.09000000e+02,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.56000000e+02,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPre(train_x, train_y, test_x, test_y, model):\n",
    "    is_dispersed = [False, True, False, False, False, True, False, False, \n",
    "                    True, False, False, False, True]\n",
    "    model.fit(train_x, train_y, is_dispersed)\n",
    "    pre_y = model.predict(test_x)\n",
    "    print 'accuracy: %f' % (accuracy_score(test_y, pre_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.852459\n"
     ]
    }
   ],
   "source": [
    "naivebayesPre(train_x, train_y, test_x, test_y, NaiveBayes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
